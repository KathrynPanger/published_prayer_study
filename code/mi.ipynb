{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('anaconda3': virtualenv)",
   "metadata": {
    "interpreter": {
     "hash": "9a492a932a5bed98d6f8e1b5f1ae1d46b2b5df4ebd9e59fb2d1181a1f217f2fd"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "from fancyimpute import KNN, NuclearNormMinimization, SoftImpute, BiScaler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bring in the recoded data\n",
    "gss_recoded=pd.read_csv(\"../GSS_1996_wreltrad.csv\", encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataset imputed with the means of each variable\n",
    "gss_means=gss_recoded.copy(deep=True)\n",
    "for varname in gss_means:\n",
    "    mean=gss_means[varname].mean()\n",
    "    gss_means.loc[(gss_means[varname].isnull()), varname] = mean\n",
    "gss_means.to_csv(\"../data/gss_means.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Imputing row 1/1114 with 631 missing, elapsed time: 18.286\n",
      "Imputing row 101/1114 with 600 missing, elapsed time: 19.404\n",
      "Imputing row 201/1114 with 627 missing, elapsed time: 20.509\n",
      "Imputing row 301/1114 with 673 missing, elapsed time: 21.611\n",
      "Imputing row 401/1114 with 609 missing, elapsed time: 22.740\n",
      "Imputing row 501/1114 with 652 missing, elapsed time: 23.925\n",
      "Imputing row 601/1114 with 596 missing, elapsed time: 25.114\n",
      "Imputing row 701/1114 with 596 missing, elapsed time: 26.323\n",
      "Imputing row 801/1114 with 628 missing, elapsed time: 27.441\n",
      "Imputing row 901/1114 with 657 missing, elapsed time: 28.635\n",
      "Imputing row 1001/1114 with 632 missing, elapsed time: 29.774\n",
      "Imputing row 1101/1114 with 620 missing, elapsed time: 30.926\n",
      "[KNN] Warning: 426662/1367992 still missing after imputation, replacing with 0\n"
     ]
    }
   ],
   "source": [
    "#Fancyimpute imputation\n",
    "# Create a dataframe with the values imputed using nearest three rows\n",
    "gss_k3=gss_recoded.copy(deep=True)\n",
    "X_filled_knn = KNN(k=3).fit_transform(gss_k3)\n",
    "gss_knn=pd.DataFrame(X_filled_knn, columns=gss_recoded.columns)\n",
    "gss_knn.to_csv(\"../data/gss_fancyimpute_knn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sklearn imputation\n",
    "##BaysianRidge method\n",
    "##10 iterations\n",
    "##3 \"nearest\" features used to estimate*\n",
    "# *(nearness determined using absolute correlation coefficient between each feature pair after initial imputation. Is this still MAR or MCAR?)\n",
    "sklearn.impute.IterativeImputer(estimator=BaysianRidge(),missing_values=np.nan,sample_posterior=True, max_iter=10, n_nearest_features=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sklearn imputation\n",
    "##BaysianRidge method\n",
    "##10 iterations\n",
    "##ALL features used to estimate\n",
    "sklearn.impute.IterativeImputer(estimator=BaysianRidge(),missing_values=np.nan,sample_posterior=True, max_iter=10, n_nearest_features=None)"
   ]
  }
 ]
}